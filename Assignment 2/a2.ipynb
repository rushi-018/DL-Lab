{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f780a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python-headless in d:\\engineering\\dl\\.venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from opencv-python-headless) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\engineering\\dl\\.venv\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (5.29.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (2.32.4)\n",
      "Requirement already satisfied: setuptools in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (2.1.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.7.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in d:\\engineering\\dl\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in d:\\engineering\\dl\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in d:\\engineering\\dl\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in d:\\engineering\\dl\\.venv\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python-headless\n",
    "%pip install tensorflow\n",
    "%pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d00f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in d:\\engineering\\dl\\.venv\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in d:\\engineering\\dl\\.venv\\lib\\site-packages (from opencv-python) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall opencv-python-headless\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b56f713a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data/class_0\\0.jpg\n",
      "Saved data/class_0\\1.jpg\n",
      "Saved data/class_0\\2.jpg\n",
      "Saved data/class_0\\3.jpg\n",
      "Saved data/class_0\\4.jpg\n",
      "Saved data/class_0\\5.jpg\n",
      "Saved data/class_0\\6.jpg\n",
      "Saved data/class_0\\7.jpg\n",
      "Saved data/class_0\\8.jpg\n",
      "Saved data/class_0\\9.jpg\n",
      "Saved data/class_0\\10.jpg\n",
      "Saved data/class_0\\11.jpg\n",
      "Saved data/class_0\\12.jpg\n",
      "Saved data/class_0\\13.jpg\n",
      "Saved data/class_0\\14.jpg\n",
      "Saved data/class_0\\15.jpg\n",
      "Saved data/class_0\\16.jpg\n",
      "Saved data/class_0\\17.jpg\n",
      "Saved data/class_0\\18.jpg\n",
      "Saved data/class_0\\19.jpg\n",
      "Saved data/class_0\\20.jpg\n",
      "Saved data/class_0\\21.jpg\n",
      "Saved data/class_0\\22.jpg\n",
      "Saved data/class_0\\23.jpg\n",
      "Saved data/class_0\\24.jpg\n",
      "Saved data/class_0\\25.jpg\n",
      "Saved data/class_0\\26.jpg\n",
      "Saved data/class_0\\27.jpg\n",
      "Saved data/class_0\\28.jpg\n",
      "Saved data/class_0\\29.jpg\n",
      "Saved data/class_0\\30.jpg\n",
      "Saved data/class_0\\31.jpg\n",
      "Saved data/class_0\\32.jpg\n",
      "Saved data/class_0\\33.jpg\n",
      "Saved data/class_0\\34.jpg\n",
      "Saved data/class_0\\35.jpg\n",
      "Saved data/class_0\\36.jpg\n",
      "Saved data/class_0\\37.jpg\n",
      "Saved data/class_0\\38.jpg\n",
      "Saved data/class_0\\39.jpg\n",
      "Saved data/class_0\\40.jpg\n",
      "Saved data/class_0\\41.jpg\n",
      "Saved data/class_0\\42.jpg\n",
      "Saved data/class_0\\43.jpg\n",
      "Saved data/class_0\\44.jpg\n",
      "Saved data/class_0\\45.jpg\n",
      "Saved data/class_0\\46.jpg\n",
      "Saved data/class_0\\47.jpg\n",
      "Saved data/class_0\\48.jpg\n",
      "Saved data/class_0\\49.jpg\n",
      "Finished capturing 50 images for label 'class_0'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def capture_faces(label, save_path='data', num_samples=50):\n",
    "    os.makedirs(f\"{save_path}/{label}\", exist_ok=True)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame from camera.\")\n",
    "            break\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            face = frame[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, (100, 100))\n",
    "            file_path = os.path.join(f\"{save_path}/{label}\", f\"{count}.jpg\")\n",
    "            cv2.imwrite(file_path, face)\n",
    "            count += 1\n",
    "            print(f\"Saved {file_path}\")\n",
    "\n",
    "            # cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        # Comment out GUI lines for Jupyter:\n",
    "        # cv2.imshow('Capturing Faces', frame)\n",
    "        # if cv2.waitKey(1) & 0xFF == ord('q') or count >= num_samples:\n",
    "        if count >= num_samples:\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    # cv2.destroyAllWindows()\n",
    "    print(f\"Finished capturing {count} images for label '{label}'.\")\n",
    "\n",
    "# Example usage:\n",
    "#capture_faces('class_1')  # You\n",
    "capture_faces('class_0')  # Friend or other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bec9664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "IMG_SIZE = 100\n",
    "\n",
    "def load_data(path='data'):\n",
    "    X, y = [], []\n",
    "    for label in os.listdir(path):\n",
    "        class_path = os.path.join(path, label)\n",
    "        for file in os.listdir(class_path):\n",
    "            img_path = os.path.join(class_path, file)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "                X.append(img)\n",
    "                y.append(0 if label == 'class_0' else 1)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = load_data()\n",
    "X = X / 255.0\n",
    "X = X.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fcfde393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Engineering\\DL\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 296ms/step - accuracy: 0.4898 - loss: 0.7317 - val_accuracy: 0.5000 - val_loss: 0.6994\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.5195 - loss: 0.6808 - val_accuracy: 1.0000 - val_loss: 0.5133\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.9797 - loss: 0.5070 - val_accuracy: 1.0000 - val_loss: 0.3610\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 0.3532 - val_accuracy: 1.0000 - val_loss: 0.1411\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 1.0000 - loss: 0.1279 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 1.0000 - loss: 0.0288 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 1.0000 - val_loss: 3.4560e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 1.0000 - loss: 8.9021e-04 - val_accuracy: 1.0000 - val_loss: 5.1037e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 1.0000 - loss: 1.9204e-04 - val_accuracy: 1.0000 - val_loss: 1.3338e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 3.3983e-05 - val_accuracy: 1.0000 - val_loss: 5.0998e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
    "model.save(\"face_classifier.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5de05276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step\n",
      "Detected: Class 1 (score: 1.00) at [230,134,161,161]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "model = load_model(\"face_classifier.h5\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = gray[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
    "        face = face / 255.0\n",
    "        face = face.reshape(1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "        pred = model.predict(face)[0][0]\n",
    "        label = \"Class 1\" if pred > 0.5 else \"Class 0\"\n",
    "        color = (0, 255, 0) if pred > 0.5 else (0, 0, 255)\n",
    "\n",
    "        # cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "        # cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        print(f\"Detected: {label} (score: {pred:.2f}) at [{x},{y},{w},{h}]\")\n",
    "\n",
    "    # Comment out GUI lines for Jupyter:\n",
    "    # cv2.imshow('Face Recognition', frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "    # Instead, break after one loop or after a certain number of frames if you want\n",
    "    break\n",
    "\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20335ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
